import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer


class LTRPredictor():
    def __init__(self, target_model: str, predictor_model_path: str) -> None:
        if "opt-125m" in predictor_model_path:
            self.tokenizer = AutoTokenizer.from_pretrained("facebook/opt-125m")
        elif "opt-350m" in predictor_model_path:
            self.tokenizer = AutoTokenizer.from_pretrained("facebook/opt-350m")
        else:
            raise NotImplementedError

        self.target_tokenizer = AutoTokenizer.from_pretrained(target_model)
        self.predictor = AutoModelForSequenceClassification.from_pretrained(predictor_model_path, local_files_only=True).eval().to("cuda")

    
    def get_score(self, prompt_token_ids: list[int]) -> float:
        prompt = self.target_tokenizer.decode(prompt_token_ids)
        input_tokens = self.tokenizer(prompt, return_tensors="pt").to("cuda")
        score = self.predictor(input_tokens['input_ids'], input_tokens['attention_mask']).logits.item()

        return score